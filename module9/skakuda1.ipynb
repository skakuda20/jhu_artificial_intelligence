{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 9 - Programming Assignment\n",
    "\n",
    "## Directions\n",
    "\n",
    "1. Change the name of this file to be your JHED id as in `jsmith299.ipynb`. Because sure you use your JHED ID (it's made out of your name and not your student id which is just letters and numbers).\n",
    "2. Make sure the notebook you submit is cleanly and fully executed. I do not grade unexecuted notebooks.\n",
    "3. Submit your notebook back in Blackboard where you downloaded this file.\n",
    "\n",
    "*Provide the output **exactly** as requested*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "For this assignment you will be implementing and evaluating a Naive Bayes Classifier with the same data from last week:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "(You should have downloaded it).\n",
    "\n",
    "<div style=\"background: lemonchiffon; margin:20px; padding: 20px;\">\n",
    "    <strong>Important</strong>\n",
    "    <p>\n",
    "        No Pandas. The only acceptable libraries in this class are those contained in the `environment.yml`. No OOP, either. You can use Dicts, NamedTuples, Data Classes, etc. as your abstract data type (ADT).\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "You'll first need to calculate all of the necessary probabilities using a `train` function. A flag will control whether or not you use \"+1 Smoothing\" or not. You'll then need to have a `classify` function that takes your probabilities, a List of instances (possibly a list of 1) and returns a List of Tuples. Each Tuple has the best class in the first position and a dict with a key for every possible class label and the associated *normalized* probability. For example, if we have given the `classify` function a list of 2 observations, we would get the following back:\n",
    "\n",
    "```\n",
    "[(\"e\", {\"e\": 0.98, \"p\": 0.02}), (\"p\", {\"e\": 0.34, \"p\": 0.66})]\n",
    "```\n",
    "\n",
    "when calculating the error rate of your classifier, you should pick the class label with the highest probability; you can write a simple function that takes the Dict and returns that class label.\n",
    "\n",
    "As a reminder, the Naive Bayes Classifier generates the *unnormalized* probabilities from the numerator of Bayes Rule:\n",
    "\n",
    "$$P(C|A) \\propto P(A|C)P(C)$$\n",
    "\n",
    "where C is the class and A are the attributes (data). Since the normalizer of Bayes Rule is the *sum* of all possible numerators and you have to calculate them all, the normalizer is just the sum of the probabilities.\n",
    "\n",
    "You will have the same basic functions as the last module's assignment and some of them can be reused or at least repurposed.\n",
    "\n",
    "`train` takes training_data and returns a Naive Bayes Classifier (NBC) as a data structure. There are many options including namedtuples and just plain old nested dictionaries. **No OOP**.\n",
    "\n",
    "```\n",
    "def train(training_data, smoothing=True):\n",
    "   # returns the \"classifier\" (however you decided to represent the probability tables).\n",
    "```\n",
    "\n",
    "The `smoothing` value defaults to True. You should handle both cases.\n",
    "\n",
    "`classify` takes a NBC produced from the function above and applies it to labeled data (like the test set) or unlabeled data (like some new data). (This is not the same `classify` as the pseudocode which classifies only one instance at a time; it can call it though).\n",
    "\n",
    "```\n",
    "def classify(nbc, observations, labeled=True):\n",
    "    # returns a list of tuples, the argmax and the raw data as per the pseudocode.\n",
    "```\n",
    "\n",
    "`evaluate` takes a data set with labels (like the training set or test set) and the classification result and calculates the classification error rate:\n",
    "\n",
    "$$error\\_rate=\\frac{errors}{n}$$\n",
    "\n",
    "Do not use anything else as evaluation metric or the submission will be deemed incomplete, ie, an \"F\". (Hint: accuracy rate is not the error rate!).\n",
    "\n",
    "`cross_validate` takes the data and uses 5x2 cross validation (from Module 2!) to `train`, `classify`, and `evaluate`. **Remember to shuffle your data before you create your folds**. I leave the exact signature of `cross_validate` to you but you should write it so that you can use it with *any* `classify` function of the same form (using higher order functions and partial application). If you did so last time, you can reuse it for this assignment.\n",
    "\n",
    "Following Module 2's materials, `cross_validate` should print out the fold number and the evaluation metric (error rate) for each fold and then the average value (and the variance). What you are looking for here is a consistent evaluation metric cross the folds. You should print the error rates in terms of percents (ie, multiply the error rate by 100 and add \"%\" to the end).\n",
    "\n",
    "To summarize...\n",
    "\n",
    "Apply the Naive Bayes Classifier algorithm to the Mushroom data set using 5x2 cross validation and the error rate as the evaluation metric. You will do this *twice*. Once with smoothing=True and once with smoothing=False. You should follow up with a brief hypothesis/explanation for the similarities or differences in the results. You may also compare the results to the Decision Tree and why you think they're different (if they are)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Functions\n",
    "\n",
    "You do not need to document these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this function to read the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file_name: str) -> list[list]:\n",
    "    data = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        datum = line.rstrip().split(\",\")\n",
    "        data.append(datum)\n",
    "    random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this function to create 10 folds for 5x2 cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(xs: list, n: int) -> list[list[list]]:\n",
    "    k, m = divmod(len(xs), n)\n",
    "    # be careful of generators...\n",
    "    return list(xs[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your code after this line:\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train\n",
    "`train` takes in training data and returns a Naive Bayes classifier, represented by a dictionary. Optionally, +1 smoothing can be toggled to help account for zero probabilities in the model. **Used by**: [cross_validate](#cross_validate)\n",
    "\n",
    "- **training_data** (list[list]): The training data where the last column is the class label\n",
    "- **smoothing** (bool): Whether to apply +1 smoothing\n",
    "\n",
    "**Returns** (dict): A dictionary representing the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train(training_data, smoothing=False):\n",
    "    class_counts = defaultdict(int)\n",
    "    feature_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "    total_instances = len(training_data)\n",
    "\n",
    "    for instance in training_data:\n",
    "        class_label = instance[-1]\n",
    "        class_counts[class_label] += 1\n",
    "        for feature_index, feature_value in enumerate(instance[:-1]):\n",
    "            feature_counts[feature_index][feature_value][class_label] += 1\n",
    "\n",
    "    classifier = {\n",
    "        \"class_probs\": {},\n",
    "        \"feature_probs\": defaultdict(lambda: defaultdict(dict)),\n",
    "        \"classes\": set(class_counts.keys())\n",
    "    }\n",
    "\n",
    "    for class_label, count in class_counts.items():\n",
    "        classifier[\"class_probs\"][class_label] = count / total_instances\n",
    "\n",
    "    for feature_index, feature_values in feature_counts.items():\n",
    "        for feature_value, class_dict in feature_values.items():\n",
    "            for class_label, count in class_dict.items():\n",
    "                if smoothing:\n",
    "                    numerator = count + 1\n",
    "                    denominator = class_counts[class_label] + len(feature_values)\n",
    "                else:\n",
    "                    numerator = count\n",
    "                    denominator = class_counts[class_label]\n",
    "                classifier[\"feature_probs\"][feature_index][feature_value][class_label] = numerator / denominator\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "        [1, 0, 'A'],\n",
    "        [1, 1, 'A'],\n",
    "        [0, 1, 'B'],\n",
    "        [0, 0, 'B']\n",
    "    ]\n",
    "classifier = train(training_data, smoothing=False)  # Test classifier without smoothing\n",
    "\n",
    "assert classifier[\"class_probs\"]['A'] == 2 / 4, \"Class probability for 'A' is incorrect\"\n",
    "assert classifier[\"class_probs\"]['B'] == 2 / 4, \"Class probability for 'B' is incorrect\"\n",
    "\n",
    "assert classifier[\"feature_probs\"][0][1]['A'] == 2 / 2, \"Feature probability for feature 0, value 1, class 'A' is incorrect\"\n",
    "assert classifier[\"feature_probs\"][0][0]['B'] == 2 / 2, \"Feature probability for feature 0, value 0, class 'B' is incorrect\"\n",
    "assert classifier[\"feature_probs\"][1][0]['A'] == 1 / 2, \"Feature probability for feature 1, value 0, class 'A' is incorrect\"\n",
    "assert classifier[\"feature_probs\"][1][1]['B'] == 1 / 2, \"Feature probability for feature 1, value 1, class 'B' is incorrect\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train(training_data, smoothing=True) # Test classifier with smoothing\n",
    "\n",
    "assert classifier[\"class_probs\"]['A'] == 2 / 4, \"Class probability for 'A' is incorrect with smoothing\"\n",
    "assert classifier[\"class_probs\"]['B'] == 2 / 4, \"Class probability for 'B' is incorrect with smoothing\"\n",
    "\n",
    "assert classifier[\"feature_probs\"][0][1]['A'] == (2 + 1) / (2 + 2), \"Feature probability for feature 0, value 1, class 'A' is incorrect with smoothing\"\n",
    "assert classifier[\"feature_probs\"][0][0]['B'] == (2 + 1) / (2 + 2), \"Feature probability for feature 0, value 0, class 'B' is incorrect with smoothing\"\n",
    "assert classifier[\"feature_probs\"][1][0]['A'] == (1 + 1) / (2 + 2), \"Feature probability for feature 1, value 0, class 'A' is incorrect with smoothing\"\n",
    "assert classifier[\"feature_probs\"][1][1]['B'] == (1 + 1) / (2 + 2), \"Feature probability for feature 1, value 1, class 'B' is incorrect with smoothing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classify\n",
    "`classify` classifies the test data by appllying the trained model  **Used by**: [cross_validate](#cross_validate)\n",
    "\n",
    "- **classifier** (dict): The trained Naive Bayes Classifier model\n",
    "- **test_data** (list[list]): The test data where the last column is the class label\n",
    "\n",
    "**Returns** (list): A list of predicted class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def classify(classifier, test_data):\n",
    "    predictions = []\n",
    "\n",
    "    for instance in test_data:\n",
    "        posteriors = {}\n",
    "\n",
    "        for class_label in classifier[\"classes\"]:\n",
    "            posterior = math.log(classifier[\"class_probs\"].get(class_label, 1e-10))  # Use a small value if missing\n",
    "\n",
    "            for feature_index, feature_value in enumerate(instance[:-1]):\n",
    "                feature_probs = classifier[\"feature_probs\"][feature_index]\n",
    "                prob = feature_probs.get(feature_value, {}).get(class_label, 1e-10)\n",
    "                posterior += math.log(prob)\n",
    "\n",
    "            posteriors[class_label] = posterior\n",
    "\n",
    "        predicted_class = max(posteriors, key=posteriors.get)\n",
    "        predictions.append(predicted_class)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    [1, 0, 'A'],\n",
    "    [1, 1, 'A'],\n",
    "    [0, 1, 'B'],\n",
    "    [0, 0, 'B']\n",
    "]\n",
    "\n",
    "classifier = train(training_data, smoothing=False)\n",
    "test_data = [\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [0, 1], \n",
    "    [0, 0],\n",
    "    [1, 1],\n",
    "]\n",
    "\n",
    "expected_predictions = ['A', 'A', 'B', 'B', 'A']\n",
    "predictions = classify(classifier, test_data)\n",
    "assert predictions == expected_predictions, f\"Test failed: {predictions} != {expected_predictions}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate\n",
    "`evaluate` evaluates the classifier by calculating the error rate  **Used by**: [cross_validate](#cross_validate)\n",
    "\n",
    "- **test_data** (list[list]): The test data where the last column is the class label\n",
    "- **predictions** (list): The predicted class labels\n",
    "\n",
    "**Returns** (float): Error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data, predictions):\n",
    "    actual_labels = [instance[-1] for instance in test_data]\n",
    "    errors = sum(1 for actual, predicted in zip(actual_labels, predictions) if actual != predicted)\n",
    "    return errors / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [\n",
    "    [1, 0, 'A'],\n",
    "    [0, 1, 'B'],\n",
    "    [1, 1, 'A']\n",
    "]\n",
    "predictions = ['A', 'B', 'A']\n",
    "error_rate = evaluate(test_data, predictions)\n",
    "assert error_rate == 0.0, f\"Expected error rate 0.0, got {error_rate}\"\n",
    "\n",
    "predictions = ['B', 'A', 'B']\n",
    "error_rate = evaluate(test_data, predictions)\n",
    "assert error_rate == 1.0, f\"Expected error rate 1.0, got {error_rate}\"\n",
    "\n",
    "predictions = ['A', 'A', 'A']\n",
    "error_rate = evaluate(test_data, predictions)\n",
    "assert error_rate == 1 / 3, f\"Expected error rate {1 / 3}, got {error_rate}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_validate\n",
    "`cross_validate` evaluates the performance of the model using 5x2 cross-validation. Prints the error rate for each fold and split.\n",
    "\n",
    "- **data** (list): The dataset to use for cross-validation where each row is a list with the first element as the label\n",
    "- **smoothing** (bool): Boolean flag to toggle +1 smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def cross_validate(data, smoothing=False):\n",
    "    clean_data = [row for row in data if '?' not in row]\n",
    "\n",
    "    total_error = 0\n",
    "\n",
    "    print(\"Fold\\tSplit\\tError Rate\")\n",
    "    for fold in range(5):\n",
    "        random.shuffle(clean_data)\n",
    "        folds = create_folds(clean_data, 2)\n",
    "\n",
    "        for split in range(2):\n",
    "            train_set = folds[1 - split]\n",
    "            test_set = folds[split]\n",
    "\n",
    "            tree = train(train_set, smoothing)\n",
    "            preds = classify(tree, test_set)\n",
    "            error = evaluate(test_set, preds)\n",
    "            total_error += error\n",
    "            error_rate = error * 100\n",
    "            print(f\"{fold+1}\\t{split+1}\\t{error_rate:.4f}%\")\n",
    "\n",
    "    average_error = total_error / 10\n",
    "    average_error_rate = average_error * 100\n",
    "    print(f\"Average Error Rate: {average_error_rate:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x2 Cross-Validation with Smoothing=True\n",
      "Fold\tSplit\tError Rate\n",
      "1\t1\t28.3841%\n",
      "1\t2\t28.2424%\n",
      "2\t1\t28.7739%\n",
      "2\t2\t27.5337%\n",
      "3\t1\t28.4196%\n",
      "3\t2\t28.0652%\n",
      "4\t1\t29.1283%\n",
      "4\t2\t27.8172%\n",
      "5\t1\t28.5259%\n",
      "5\t2\t27.9943%\n",
      "Average Error Rate: 28.2884%\n",
      "\n",
      "5x2 Cross-Validation with Smoothing=False\n",
      "Fold\tSplit\tError Rate\n",
      "1\t1\t28.1715%\n",
      "1\t2\t28.4904%\n",
      "2\t1\t29.2346%\n",
      "2\t2\t27.2147%\n",
      "3\t1\t27.3565%\n",
      "3\t2\t29.2346%\n",
      "4\t1\t27.8880%\n",
      "4\t2\t28.8448%\n",
      "5\t1\t27.4628%\n",
      "5\t2\t29.1991%\n",
      "Average Error Rate: 28.3097%\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_file = \"agaricus-lepiota.data\"\n",
    "data = parse_data(data_file)\n",
    "\n",
    "print(\"5x2 Cross-Validation with Smoothing=True\")\n",
    "cross_validate(data, True)\n",
    "\n",
    "print(\"\\n5x2 Cross-Validation with Smoothing=False\")\n",
    "cross_validate(data, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier achieved an average error rate of 28%. This suggets that the strong independene assumption made by NB does not hold well for this dataset. Applying +1 smoothing led to very marginal improvements, indicating the model was not significantly affected by zero probabilities. We can assume that this dataset is limited more by independence than sparsity. \n",
    "\n",
    "In comparison to the Decision Tree model, which had a near zero error rate, NB was unable to model the more complex feature relationships. While NB is simpler and faster, it can underperform in cases with stronger feature independence, whereas a decision tree can adapt to fit such patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before You Submit...\n",
    "\n",
    "1. Did you provide output exactly as requested?\n",
    "2. Did you re-execute the entire notebook? (\"Restart Kernel and Rull All Cells...\")\n",
    "3. If you did not complete the assignment or had difficulty please explain what gave you the most difficulty in the Markdown cell below.\n",
    "4. Did you change the name of the file to `jhed_id.ipynb`?\n",
    "\n",
    "Do not submit any other files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "81px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
